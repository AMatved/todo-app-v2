# –ü–ª–∞–Ω –∏–∑—É—á–µ–Ω–∏—è Machine Learning –∏ Computer Vision –∑–∞ 30 –¥–Ω–µ–π
# –¶–µ–ª—å: –ù–∞—É—á–∏—Ç—å—Å—è –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å —Å–ø—É—Ç–Ω–∏–∫–æ–≤—ã–µ —Å–Ω–∏–º–∫–∏ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º PyTorch

---

## üìÖ –ù–µ–¥–µ–ª—è 1: –§—É–Ω–¥–∞–º–µ–Ω—Ç Python –∏ –æ—Å–Ω–æ–≤—ã –¥–∞–Ω–Ω—ã—Ö
**–¶–µ–ª—å:** –û—Å–≤–æ–∏—Ç—å Python –Ω–∞ —É—Ä–æ–≤–Ω–µ sufficient –¥–ª—è ML

### –î–µ–Ω—å 1-2: Python Basics (4-6 —á–∞—Å–æ–≤)
**–†–µ—Å—É—Ä—Å—ã:**
- üìπ [Kaggle Python Course](https://www.kaggle.com/learn/python) - –ë–ï–°–ü–õ–ê–¢–ù–û
- üìñ [Python.org Official Tutorial](https://docs.python.org/3/tutorial/) - —Ä–∞–∑–¥–µ–ª—ã 1-5

**–ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –∑–∞–¥–∞–Ω–∏—è:**
```python
# Day 1: Basics
- –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ, —Ç–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö (int, float, str, bool)
- –û–ø–µ—Ä–∞—Ç–æ—Ä—ã (+, -, *, /, //, %, **)
- –£—Å–ª–æ–≤–∏—è (if/elif/else)
- –¶–∏–∫–ª—ã (for, while)

# Day 2: Functions & Data Structures
- –§—É–Ω–∫—Ü–∏–∏ (def, return, args, kwargs)
- –°–ø–∏—Å–∫–∏ (list) –∏ –º–µ—Ç–æ–¥—ã: append, pop, sort
- –°–ª–æ–≤–∞—Ä–∏ (dict) –∏ –º–µ—Ç–æ–¥—ã: keys, values, items
- –ö–æ—Ä—Ç–µ–∂–∏ (tuple) –∏ –º–Ω–æ–∂–µ—Å—Ç–≤–∞ (set)
```

**–ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–Ω–∞–Ω–∏–π:**
- [ ] –ù–∞–ø–∏—Å–∞—Ç—å —Ñ—É–Ω–∫—Ü–∏—é, –∫–æ—Ç–æ—Ä–∞—è —Å–æ—Ä—Ç–∏—Ä—É–µ—Ç —Å–ø–∏—Å–æ–∫ —á–∏—Å–µ–ª
- [ ] –°–æ–∑–¥–∞—Ç—å —Å–ª–æ–≤–∞—Ä—å —Å–æ —Å—Ç—É–¥–µ–Ω—Ç–∞–º–∏ –∏ –∏—Ö –æ—Ü–µ–Ω–∫–∞–º–∏
- [ ] –†–µ—à–∏—Ç—å 5 –∑–∞–¥–∞—á –Ω–∞ [Codewars](https://www.codewars.com/) (–ª–µ–≥–∫–∏–π —É—Ä–æ–≤–µ–Ω—å)

---

### –î–µ–Ω—å 3-4: NumPy –∏ Pandas (6-8 —á–∞—Å–æ–≤)
**–†–µ—Å—É—Ä—Å—ã:**
- üìπ [Kaggle Pandas Course](https://www.kaggle.com/learn/pandas) - –ë–ï–°–ü–õ–ê–¢–ù–û
- üìπ [Kaggle NumPy Course](https://www.kaggle.com/learn/numpy) - –ë–ï–°–ü–õ–ê–¢–ù–û
- üìñ [NumPy Quick Start](https://numpy.org/doc/stable/user/quickstart.html)

**–ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –∑–∞–¥–∞–Ω–∏—è:**
```python
# Day 3: NumPy
import numpy as np

# –°–æ–∑–¥–∞—Ç—å –º–∞—Å—Å–∏–≤—ã
arr = np.array([1, 2, 3, 4, 5])
zeros = np.zeros((3, 3))
ones = np.ones((2, 4))
random = np.random.randn(3, 3)

# –ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –æ–ø–µ—Ä–∞—Ü–∏–∏
mean = np.mean(arr)
std = np.std(arr)
matrix_mult = np.dot(arr, arr)

# Indexing & slicing
subset = arr[1:4]
boolean_mask = arr > 2

# Day 4: Pandas
import pandas as pd

# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
df = pd.read_csv('data.csv')

# –ë–∞–∑–æ–≤—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏
df.head()  # –ø–µ—Ä–≤—ã–µ 5 —Å—Ç—Ä–æ–∫
df.describe()  # —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
df['column'].mean()  # —Å—Ä–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ

# –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è
filtered = df[df['age'] > 25]

# –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞
grouped = df.groupby('category').mean()
```

**–ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–Ω–∞–Ω–∏–π:**
- [ ] –°–æ–∑–¥–∞—Ç—å numpy –º–∞—Å—Å–∏–≤ 10x10 —Å–æ —Å–ª—É—á–∞–π–Ω—ã–º–∏ —á–∏—Å–ª–∞–º–∏
- [ ] –ù–∞–π—Ç–∏ —Å—Ä–µ–¥–Ω–µ–µ, –º–µ–¥–∏–∞–Ω—É, —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ
- [ ] –ó–∞–≥—Ä—É–∑–∏—Ç—å CSV —Å –¥–∞–Ω–Ω—ã–º–∏ –≤ Pandas
- [ ] –°–¥–µ–ª–∞—Ç—å groupby –∏ –∞–≥—Ä–µ–≥–∞—Ü–∏—é

---

### –î–µ–Ω—å 5-7: –í–≤–µ–¥–µ–Ω–∏–µ –≤ Machine Learning (8-10 —á–∞—Å–æ–≤)
**–†–µ—Å—É—Ä—Å—ã:**
- üìπ [Andrew Ng - Machine Learning (Week 1-2)](https://www.coursera.org/learn/machine-learning)
  - –ë–ï–°–ü–õ–ê–¢–ù–û (audit mode)
- üìñ [Scikit-learn User Guide](https://scikit-learn.org/stable/user_guide.html)

**–¢–µ–æ—Ä–∏—è –¥–ª—è –∏–∑—É—á–µ–Ω–∏—è:**
- –ß—Ç–æ —Ç–∞–∫–æ–µ Machine Learning?
- Supervised vs Unsupervised learning
- Linear Regression
- Loss functions (MSE, MAE)
- Overfitting vs Underfitting
- Train/Test split

**–ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –∑–∞–¥–∞–Ω–∏—è:**
```python
# Day 5-6: Scikit-learn Basics
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error
import matplotlib.pyplot as plt

# –°–æ–∑–¥–∞—Ç—å dummy –¥–∞–Ω–Ω—ã–µ
import numpy as np
X = np.random.randn(100, 1)
y = 2 * X + 1 + np.random.randn(100, 1) * 0.5

# Split –¥–∞–Ω–Ω—ã–µ
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# –û–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å
model = LinearRegression()
model.fit(X_train, y_train)

# –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
y_pred = model.predict(X_test)

# –û—Ü–µ–Ω–∫–∞
mse = mean_squared_error(y_test, y_pred)
print(f"MSE: {mse}")

# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
plt.scatter(X_test, y_test, color='blue')
plt.plot(X_test, y_pred, color='red')
plt.show()

# Day 7: –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score

from sklearn.datasets import make_classification
X, y = make_classification(n_samples=1000, n_features=20)

X_train, X_test, y_train, y_test = train_test_split(X, y)

model = RandomForestClassifier()
model.fit(X_train, y_train)
y_pred = model.predict(X_test)

acc = accuracy_score(y_test, y_pred)
print(f"Accuracy: {acc}")
```

**–ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–Ω–∞–Ω–∏–π:**
- [ ] –û–±—É—á–∏—Ç—å Linear Regression –Ω–∞ —Å–≤–æ–∏—Ö –¥–∞–Ω–Ω—ã—Ö
- [ ] –û–±—É—á–∏—Ç—å –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä (Random Forest)
- [ ] –ü–æ—Å—Ç—Ä–æ–∏—Ç—å –≥—Ä–∞—Ñ–∏–∫ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
- [ ] –ü–æ–Ω–∏–º–∞—Ç—å —á—Ç–æ —Ç–∞–∫–æ–µ overfitting

---

## üìÖ –ù–µ–¥–µ–ª—è 2: Computer Vision –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
**–¶–µ–ª—å:** –ù–∞—É—á–∏—Ç—å—Å—è —Ä–∞–±–æ—Ç–∞—Ç—å —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏ –¥–ª—è —Å–ø—É—Ç–Ω–∏–∫–æ–≤—ã—Ö —Å–Ω–∏–º–∫–æ–≤

### –î–µ–Ω—å 8-9: –û—Å–Ω–æ–≤—ã –∫–æ–º–ø—å—é—Ç–µ—Ä–Ω–æ–≥–æ –∑—Ä–µ–Ω–∏—è (6-8 —á–∞—Å–æ–≤)
**–†–µ—Å—É—Ä—Å—ã:**
- üìπ [OpenCV Python Tutorial](https://www.youtube.com/watch?v=oXlwWbU8l2o) - FreeCodeCamp (1-2 —á–∞—Å–∞)
- üìñ [OpenCV Python Docs](https://docs.opencv.org/4.x/d6/d00/tutorial_py_root.html)
- üìñ [Image Processing Basics](https://www.learnopencv.com/)

**–£—Å—Ç–∞–Ω–æ–≤–∫–∞:**
```bash
pip install opencv-python matplotlib pillow
```

**–ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –∑–∞–¥–∞–Ω–∏—è:**
```python
# Day 8: OpenCV Basics
import cv2
import numpy as np
import matplotlib.pyplot as plt

# –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
img = cv2.imread('satellite_image.jpg')

# –†–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
height, width = img.shape[:2]
print(f"Size: {width}x{height}")

# –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è —Ü–≤–µ—Ç–æ–≤—ã—Ö –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤
gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)

# –ò–∑–º–µ–Ω–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞
resized = cv2.resize(img, (512, 512))

# –û–±—Ä–µ–∑–∫–∞
cropped = img[100:400, 200:500]

# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
plt.figure(figsize=(15, 5))
plt.subplot(131)
plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
plt.title('Original')
plt.subplot(132)
plt.imshow(gray, cmap='gray')
plt.title('Grayscale')
plt.subplot(133)
plt.imshow(cv2.cvtColor(hsv, cv2.COLOR_HSV2RGB))
plt.title('HSV')
plt.show()

# Day 9: –§–∏–ª—å—Ç—Ä—ã –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞
# –†–∞–∑–º—ã—Ç–∏–µ
blurred = cv2.GaussianBlur(img, (5, 5), 0)

# –†–µ–∑–∫–æ—Å—Ç—å
kernel = np.array([[-1,-1,-1],
                   [-1, 9,-1],
                   [-1,-1,-1]])
sharpened = cv2.filter2D(img, -1, kernel)

# –î–µ—Ç–µ–∫—Ü–∏—è –∫—Ä–∞–µ–≤
edges = cv2.Canny(gray, 100, 200)

# –ü–æ—Ä–æ–≥–æ–≤–∞—è –±–∏–Ω–∞—Ä–∏–∑–∞—Ü–∏—è
_, thresh = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)

# –ú–æ—Ä—Ñ–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ –æ–ø–µ—Ä–∞—Ü–∏–∏
kernel = np.ones((5,5), np.uint8)
erosion = cv2.erode(thresh, kernel, iterations=1)
dilation = cv2.dilate(thresh, kernel, iterations=1)
```

**–ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–Ω–∞–Ω–∏–π:**
- [ ] –ó–∞–≥—Ä—É–∑–∏—Ç—å —Å–ø—É—Ç–Ω–∏–∫–æ–≤—ã–π —Å–Ω–∏–º–æ–∫
- [ ] –ü—Ä–∏–º–µ–Ω–∏—Ç—å 5 —Ä–∞–∑–Ω—ã—Ö —Ñ–∏–ª—å—Ç—Ä–æ–≤
- [ ] –°–¥–µ–ª–∞—Ç—å –¥–µ—Ç–µ–∫—Ü–∏—é –∫—Ä–∞–µ–≤
- [ ] –°–æ–∑–¥–∞—Ç—å —Ñ—É–Ω–∫—Ü–∏—é –¥–ª—è –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥–∞

---

### –î–µ–Ω—å 10-11: –†–∞–±–æ—Ç–∞ —Å–æ —Å–ø—É—Ç–Ω–∏–∫–æ–≤—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏ (8-10 —á–∞—Å–æ–≤)
**–†–µ—Å—É—Ä—Å—ã:**
- üìñ [Rasterio Documentation](https://rasterio.readthedocs.io/)
- üìñ [Geopandas Tutorial](https://geopandas.org/en/stable/getting_started.html)
- üìπ [Satellite Image Analysis Tutorial](https://www.youtube.com/watch?v=DaLBpC_JjVc)

**–£—Å—Ç–∞–Ω–æ–≤–∫–∞:**
```bash
pip install rasterio geopandas shapely
```

**–ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –∑–∞–¥–∞–Ω–∏—è:**
```python
# Day 10: Rasterio - —á—Ç–µ–Ω–∏–µ —Å–ø—É—Ç–Ω–∏–∫–æ–≤—ã—Ö —Å–Ω–∏–º–∫–æ–≤
import rasterio
from rasterio.plot import show
import matplotlib.pyplot as plt
import numpy as np

# –û—Ç–∫—Ä—ã—Ç–∏–µ GeoTIFF —Ñ–∞–π–ª–∞
with rasterio.open('satellite_image.tif') as src:
    print(f"CRS: {src.crs}")  # –°–∏—Å—Ç–µ–º–∞ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç
    print(f"Transform: {src.transform}")
    print(f"Bounds: {src.bounds}")

    # –ß—Ç–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
    image = src.read()
    print(f"Shape: {image.shape}")  # (bands, height, width)

    # RGB –∫–∞–Ω–∞–ª—ã
    red = image[0]
    green = image[1]
    blue = image[2]
    nir = image[3]  # Near Infrared, –µ—Å–ª–∏ –µ—Å—Ç—å

    # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
    fig, axes = plt.subplots(2, 2, figsize=(12, 12))

    axes[0,0].imshow(red, cmap='Reds')
    axes[0,0].set_title('Red Band')

    axes[0,1].imshow(green, cmap='Greens')
    axes[0,1].set_title('Green Band')

    axes[1,0].imshow(blue, cmap='Blues')
    axes[1,0].set_title('Blue Band')

    # RGB –∫–æ–º–ø–æ–∑–∏—Ç
    rgb = np.dstack((red, green, blue))
    rgb_normalized = rgb / rgb.max()
    axes[1,1].imshow(rgb_normalized)
    axes[1,1].set_title('RGB Composite')

    plt.tight_layout()
    plt.savefig('satellite_bands.png')

# Day 11: NDVI (Vegetation Index)
def calculate_ndvi(red_band, nir_band):
    """
    NDVI = (NIR - Red) / (NIR + Red)
    Values: -1 to 1
    - -1 to 0: Water, barren areas
    - 0 to 1: Vegetation (higher = more vegetation)
    """
    ndvi = (nir_band.astype(float) - red_band.astype(float)) / \
           (nir_band + red_band)
    return ndvi

# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
ndvi = calculate_ndvi(red, nir)

# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è NDVI
plt.figure(figsize=(10, 8))
plt.imshow(ndvi, cmap='RdYlGn', vmin=-1, vmax=1)
plt.colorbar(label='NDVI')
plt.title('Vegetation Index (NDVI)')
plt.savefig('ndvi_map.png')

# –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –ø–æ NDVI
vegetation_mask = ndvi > 0.4  # –ü–æ—Ä–æ–≥ –¥–ª—è —Ä–∞—Å—Ç–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
water_mask = ndvi < 0
barren_mask = (ndvi >= 0) & (ndvi <= 0.4)

print(f"Vegetation coverage: {np.sum(vegetation_mask) / ndvi.size * 100:.2f}%")
print(f"Water coverage: {np.sum(water_mask) / ndvi.size * 100:.2f}%")
```

**–ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–Ω–∞–Ω–∏–π:**
- [ ] –û—Ç–∫—Ä—ã—Ç—å GeoTIFF —Ñ–∞–π–ª —Å –ø–æ–º–æ—â—å—é Rasterio
- [ ] –í–∏–∑—É–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ä–∞–∑–Ω—ã–µ —Å–ø–µ–∫—Ç—Ä–∞–ª—å–Ω—ã–µ –∫–∞–Ω–∞–ª—ã
- [ ] –†–∞—Å—Å—á–∏—Ç–∞—Ç—å NDVI –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
- [ ] –°–æ–∑–¥–∞—Ç—å –º–∞—Å–∫—É —Ä–∞—Å—Ç–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏

---

### –î–µ–Ω—å 12-14: PyTorch Basics (10-12 —á–∞—Å–æ–≤)
**–†–µ—Å—É—Ä—Å—ã:**
- üìπ [PyTorch 60 Minute Blitz](https://pytorch.org/tutorials/beginner/blitz/tensor_tutorial.html)
- üìπ [PyTorch Deep Learning with Python](https://www.youtube.com/watch?v=c36lU1MAp4Y)
- üìñ [PyTorch Documentation](https://pytorch.org/docs/stable/)

**–£—Å—Ç–∞–Ω–æ–≤–∫–∞:**
```bash
pip install torch torchvision torchaudio
```

**–ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –∑–∞–¥–∞–Ω–∏—è:**
```python
# Day 12: Tensors and Autograd
import torch
import torch.nn as nn

# –°–æ–∑–¥–∞–Ω–∏–µ —Ç–µ–Ω–∑–æ—Ä–æ–≤
x = torch.tensor([1, 2, 3, 4])
y = torch.zeros(2, 3)
z = torch.randn(3, 3)

# –û–ø–µ—Ä–∞—Ü–∏–∏
a = torch.tensor([1, 2, 3])
b = torch.tensor([4, 5, 6])
c = a + b  # [5, 7, 9]
d = a * b  # [4, 10, 18]
e = torch.matmul(a, b)  # dot product: 32

# GPU –ø–æ–¥–¥–µ—Ä–∂–∫–∞
if torch.cuda.is_available():
    device = torch.device('cuda')
    x = x.to(device)

# Autograd (–∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –¥–∏—Ñ—Ñ–µ—Ä–µ–Ω—Ü–∏—Ä–æ–≤–∞–Ω–∏–µ)
x = torch.tensor([2.0], requires_grad=True)
y = x ** 2 + 3 * x + 1
y.backward()
print(x.grad)  # dy/dx = 2x + 3 = 7

# Day 13: Neural Network
class SimpleNN(nn.Module):
    def __init__(self):
        super().__init__()
        self.fc1 = nn.Linear(784, 128)
        self.fc2 = nn.Linear(128, 64)
        self.fc3 = nn.Linear(64, 10)
        self.relu = nn.ReLU()

    def forward(self, x):
        x = x.view(-1, 784)  # flatten
        x = self.relu(self.fc1(x))
        x = self.relu(self.fc2(x))
        x = self.fc3(x)
        return x

model = SimpleNN()
print(model)

# Day 14: Training Loop
import torch.optim as optim

# –§—É–Ω–∫—Ü–∏—è –ø–æ—Ç–µ—Ä—å –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

# Dummy –¥–∞–Ω–Ω—ã–µ
X_train = torch.randn(1000, 784)
y_train = torch.randint(0, 10, (1000,))

# Training loop
num_epochs = 10

for epoch in range(num_epochs):
    optimizer.zero_grad()
    outputs = model(X_train)
    loss = criterion(outputs, y_train)
    loss.backward()
    optimizer.step()

    if (epoch + 1) % 2 == 0:
        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')
```

**–ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–Ω–∞–Ω–∏–π:**
- [ ] –°–æ–∑–¥–∞—Ç—å –∏ –º–∞–Ω–∏–ø—É–ª–∏—Ä–æ–≤–∞—Ç—å —Ç–µ–Ω–∑–æ—Ä–∞–º–∏
- [ ] –ù–∞–ø–∏—Å–∞—Ç—å –ø—Ä–æ—Å—Ç—É—é –Ω–µ–π—Ä–æ—Å–µ—Ç—å
- [ ] –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å training loop
- [ ] –ü–æ–Ω–∏–º–∞—Ç—å backpropagation

---

## üìÖ –ù–µ–¥–µ–ª—è 3: Deep Learning –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
**–¶–µ–ª—å:** –ü–æ—Å—Ç—Ä–æ–∏—Ç—å CNN –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π

### –î–µ–Ω—å 15-17: Convolutional Neural Networks (12-15 —á–∞—Å–æ–≤)
**–†–µ—Å—É—Ä—Å—ã:**
- üìπ [CS231n: CNNs for Visual Recognition](https://www.youtube.com/playlist?list=PL3FW7Lu3i5JvHM8ljYj-zLfQRF3EO8sYv)
  - Lectures 1-5 (MIT/Stanford)
- üìñ [CNN Explainer](https://poloclub.github.io/cnn-explainer/)
- üìπ [PyTorch CNN Tutorial](https://www.youtube.com/watch?v=pDdP0TEz90E)

**–¢–µ–æ—Ä–∏—è –¥–ª—è –∏–∑—É—á–µ–Ω–∏—è:**
- Convolution (—Å–≤–µ—Ä—Ç–∫–∞)
- Pooling (max pooling, average pooling)
- –°—Ç—Ä–æ–µ–Ω–∏–µ CNN (conv layers + fully connected)
- Famous architectures: LeNet, AlexNet, VGG, ResNet

**–ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –∑–∞–¥–∞–Ω–∏—è:**
```python
# Day 15-16: –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ CNN
import torch
import torch.nn as nn
import torch.nn.functional as F

class SatelliteCNN(nn.Module):
    def __init__(self, num_classes=5):
        super().__init__()
        # Convolutional layers
        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)
        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)
        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)

        # Pooling
        self.pool = nn.MaxPool2d(2, 2)

        # Fully connected layers
        self.fc1 = nn.Linear(128 * 28 * 28, 512)
        self.fc2 = nn.Linear(512, num_classes)

        # Dropout
        self.dropout = nn.Dropout(0.5)

    def forward(self, x):
        # Block 1
        x = F.relu(self.conv1(x))
        x = self.pool(x)  # 224 -> 112

        # Block 2
        x = F.relu(self.conv2(x))
        x = self.pool(x)  # 112 -> 56

        # Block 3
        x = F.relu(self.conv3(x))
        x = self.pool(x)  # 56 -> 28

        # Flatten
        x = x.view(-1, 128 * 28 * 28)

        # FC layers
        x = F.relu(self.fc1(x))
        x = self.dropout(x)
        x = self.fc2(x)

        return x

# –°–æ–∑–¥–∞—Ç—å –º–æ–¥–µ–ª—å
model = SatelliteCNN(num_classes=5)
print(model)

# Day 17: Training —Å —Ä–µ–∞–ª—å–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms

# –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏ –¥–ª—è –¥–∞–Ω–Ω—ã—Ö
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                       std=[0.229, 0.224, 0.225])
])

# Custom Dataset –¥–ª—è —Å–ø—É—Ç–Ω–∏–∫–æ–≤—ã—Ö —Å–Ω–∏–º–∫–æ–≤
class SatelliteDataset(Dataset):
    def __init__(self, images, labels, transform=None):
        self.images = images
        self.labels = labels
        self.transform = transform

    def __len__(self):
        return len(self.images)

    def __getitem__(self, idx):
        image = self.images[idx]
        label = self.labels[idx]

        if self.transform:
            image = self.transform(image)

        return image, label

# –°–æ–∑–¥–∞—Ç—å dataloaders
train_dataset = SatelliteDataset(X_train, y_train, transform=transform)
train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)

# Training
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = SatelliteCNN(num_classes=5).to(device)
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

num_epochs = 20
for epoch in range(num_epochs):
    model.train()
    running_loss = 0.0

    for images, labels in train_loader:
        images, labels = images.to(device), labels.to(device)

        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        running_loss += loss.item()

    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}')
```

**–ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–Ω–∞–Ω–∏–π:**
- [ ] –ü–æ–Ω–∏–º–∞—Ç—å –∫–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç convolution
- [ ] –ü–æ—Å—Ç—Ä–æ–∏—Ç—å —Å–≤–æ—é CNN
- [ ] –û–±—É—á–∏—Ç—å –Ω–∞ –¥–∞—Ç–∞—Å–µ—Ç–µ
- [ ] –î–æ—Å—Ç–∏—á—å accuracy > 70%

---

### –î–µ–Ω—å 18-19: Transfer Learning (8-10 —á–∞—Å–æ–≤)
**–†–µ—Å—É—Ä—Å—ã:**
- üìñ [PyTorch Transfer Learning Tutorial](https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html)
- üìñ [ResNet Paper](https://arxiv.org/abs/1512.03385)
- üìñ [EfficientNet Paper](https://arxiv.org/abs/1905.11946)

**–ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –∑–∞–¥–∞–Ω–∏—è:**
```python
# Day 18-19: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
import torch
import torch.nn as nn
import torchvision.models as models

# –ó–∞–≥—Ä—É–∑–∏—Ç—å –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã–π ResNet
model = models.resnet50(pretrained=True)

# –ó–∞–º–æ—Ä–æ–∑–∏—Ç—å —Å–ª–æ–∏
for param in model.parameters():
    param.requires_grad = False

# –ó–∞–º–µ–Ω–∏—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–π —Å–ª–æ–π
num_ftrs = model.fc.in_features
model.fc = nn.Linear(num_ftrs, 5)  # 5 –∫–ª–∞—Å—Å–æ–≤

# Unfreeze –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Å–ª–æ–µ–≤
for param in model.layer4.parameters():
    param.requires_grad = True

# Training (—Ç–æ–ª—å–∫–æ unfrozen —Å–ª–æ–∏)
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = model.to(device)

criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.0001)

# ... training loop –∫–∞–∫ –æ–±—ã—á–Ω–æ ...
```

**–ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–Ω–∞–Ω–∏–π:**
- [ ] –ó–∞–≥—Ä—É–∑–∏—Ç—å –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å
- [ ] –°–¥–µ–ª–∞—Ç—å fine-tuning –¥–ª—è —Å–≤–æ–µ–π –∑–∞–¥–∞—á–∏
- [ ] –°—Ä–∞–≤–Ω–∏—Ç—å —Å –æ–±—É—á–µ–Ω–∏–µ–º —Å –Ω—É–ª—è

---

### –î–µ–Ω—å 20-21: Data Augmentation (6-8 —á–∞—Å–æ–≤)
**–†–µ—Å—É—Ä—Å—ã:**
- üìñ [Albumentations Docs](https://albumentations.ai/docs/)
- üìñ [torchvision.transforms](https://pytorch.org/vision/stable/transforms.html)

**–£—Å—Ç–∞–Ω–æ–≤–∫–∞:**
```bash
pip install albumentations
```

**–ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –∑–∞–¥–∞–Ω–∏—è:**
```python
import albumentations as A
from albumentations.pytorch import ToTensorV2

# –ê—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –¥–ª—è —Å–ø—É—Ç–Ω–∏–∫–æ–≤—ã—Ö —Å–Ω–∏–º–∫–æ–≤
train_transform = A.Compose([
    A.RandomCrop(224, 224),
    A.HorizontalFlip(p=0.5),
    A.VerticalFlip(p=0.5),
    A.RandomRotate90(p=0.5),
    A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=45, p=0.5),
    A.OneOf([
        A.GaussNoise(p=1.0),
        A.GaussianBlur(p=1.0),
        A.MotionBlur(p=1.0),
    ], p=0.3),
    A.RandomBrightnessContrast(p=0.5),
    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
    ToTensorV2(),
])

# –ü—Ä–∏–º–µ–Ω–∏—Ç—å –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏
import cv2
image = cv2.imread('satellite.jpg')
image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

augmented = train_transform(image=image)
image_tensor = augmented['image']

# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–π
fig, axes = plt.subplots(2, 5, figsize=(20, 8))
for i in range(10):
    aug = train_transform(image=image)
    axes[i//5, i%5].imshow(aug['image'].permute(1, 2, 0))
plt.savefig('augmentations.png')
```

**–ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–Ω–∞–Ω–∏–π:**
- [ ] –ü—Ä–∏–º–µ–Ω–∏—Ç—å 5+ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–π
- [ ] –í–∏–∑—É–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
- [ ] –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≤ training pipeline

---

## üìÖ –ù–µ–¥–µ–ª—è 4: Semi-supervised Learning –∏ Final Project
**–¶–µ–ª—å:** –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å semi-supervised –ø–æ–¥—Ö–æ–¥ —Å –ø—Ä–æ–º–ø—Ç–∞–º–∏

### –î–µ–Ω—å 22-24: Semi-supervised Learning (10-12 —á–∞—Å–æ–≤)
**–†–µ—Å—É—Ä—Å—ã:**
- üìñ [Semi-supervised Learning Survey](https://arxiv.org/abs/2006.11148)
- üìñ [CLIP Paper](https://arxiv.org/abs/2103.00020)
- üìñ [Segment Anything Model (SAM)](https://arxiv.org/abs/2304.02643)

**–ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –∑–∞–¥–∞–Ω–∏—è:**
```python
# Day 22-23: Pseudo-labeling (–ø—Ä–æ—Å—Ç–æ–π semi-supervised –º–µ—Ç–æ–¥)
import torch.nn.functional as F

def pseudo_labeling(model, labeled_loader, unlabeled_loader, num_epochs=10):
    """
    Semi-supervised learning —Å pseudo-labels

    1. –û–±—É—á–∞–µ–º –Ω–∞ —Ä–∞–∑–º–µ—á–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    2. –ü—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ–º –º–µ—Ç–∫–∏ –¥–ª—è –Ω–µ—Ä–∞–∑–º–µ—á–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    3. –ò—Å–ø–æ–ª—å–∑—É–µ–º —É–≤–µ—Ä–µ–Ω–Ω—ã–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –∫–∞–∫ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
    """
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model = model.to(device)
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=0.001)

    for epoch in range(num_epochs):
        # Step 1: Train on labeled data
        model.train()
        labeled_loss = 0.0

        for images, labels in labeled_loader:
            images, labels = images.to(device), labels.to(device)

            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

            labeled_loss += loss.item()

        # Step 2: Generate pseudo-labels
        model.eval()
        pseudo_data = []
        pseudo_labels = []

        with torch.no_grad():
            for images in unlabeled_loader:
                images = images.to(device)
                outputs = model(images)
                probs = F.softmax(outputs, dim=1)
                confidences, predictions = torch.max(probs, dim=1)

                # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ —É–≤–µ—Ä–µ–Ω–Ω—ã–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
                confident_mask = confidences > 0.9
                if confident_mask.any():
                    pseudo_data.append(images[confident_mask])
                    pseudo_labels.append(predictions[confident_mask])

        # Step 3: Train on pseudo-labeled data
        if len(pseudo_data) > 0:
            pseudo_data = torch.cat(pseudo_data)
            pseudo_labels = torch.cat(pseudo_labels)

            pseudo_outputs = model(pseudo_data)
            pseudo_loss = criterion(pseudo_outputs, pseudo_labels)

            optimizer.zero_grad()
            pseudo_loss.backward()
            optimizer.step()

            print(f'Epoch {epoch+1}: Labeled Loss: {labeled_loss/len(labeled_loader):.4f}, '
                  f'Pseudo Loss: {pseudo_loss.item():.4f}')
        else:
            print(f'Epoch {epoch+1}: Labeled Loss: {labeled_loss/len(labeled_loader):.4f}')

    return model

# Day 24: CLIP –¥–ª—è text-prompts
# –£—Å—Ç–∞–Ω–æ–≤–∫–∞: pip install git+https://github.com/openai/CLIP.git
import clip
from PIL import Image

device = "cuda" if torch.cuda.is_available() else "cpu"
model, preprocess = clip.load("ViT-B/32", device=device)

# Text prompts –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Ä–∞—Å—Ç–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
prompts = [
    "a photo of dense forest",
    "a photo of grassland",
    "a photo of wetland",
    "a photo of desert",
    "a photo of urban area"
]

# –ó–∞–≥—Ä—É–∑–∏—Ç—å —Å–ø—É—Ç–Ω–∏–∫–æ–≤—ã–π —Å–Ω–∏–º–æ–∫
image = preprocess(Image.open("satellite.jpg")).unsqueeze(0).to(device)
text = clip.tokenize(prompts).to(device)

# –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
with torch.no_grad():
    image_features = model.encode_image(image)
    text_features = model.encode_text(text)

    # Calculate similarity
    logits_per_image = (image_features @ text_features.T).softmax(dim=-1)
    probs = logits_per_image.cpu().numpy()[0]

# –ü–æ–∫–∞–∑–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
for prompt, prob in zip(prompts, probs):
    print(f"{prompt}: {prob*100:.2f}%")
```

**–ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–Ω–∞–Ω–∏–π:**
- [ ] –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å pseudo-labeling
- [ ] –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å CLIP –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
- [ ] –°—Ä–∞–≤–Ω–∏—Ç—å —Å supervised –ø–æ–¥—Ö–æ–¥–æ–º

---

### –î–µ–Ω—å 25-28: Final Project (16-20 —á–∞—Å–æ–≤)
**–¶–µ–ª—å:** –°–æ–∑–¥–∞—Ç—å –ø–æ–ª–Ω—É—é —Å–∏—Å—Ç–µ–º—É –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Å–ø—É—Ç–Ω–∏–∫–æ–≤—ã—Ö —Å–Ω–∏–º–∫–æ–≤

**–ü—Ä–æ–µ–∫—Ç: Vegetation Classification Web App**

**–®–∞–≥ 1: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö (Day 25)**
```python
# –°–∫–∞—á–∞–π—Ç–µ –¥–∞—Ç–∞—Å–µ—Ç EuroSAT
# https://github.com/phelber/EuroSAT

import requests
import zipfile
from pathlib import Path

# –°–∫–∞—á–∞—Ç—å
url = "https://madm.dfki.de/files/sentinel/EuroSAT.zip"
response = requests.get(url, stream=True)

with open("EuroSAT.zip", "wb") as f:
    for chunk in response.iter_content(chunk_size=8192):
        f.write(chunk)

# –†–∞–∑–∞—Ä—Ö–∏–≤–∏—Ä–æ–≤–∞—Ç—å
with zipfile.ZipFile("EuroSAT.zip", "r") as zip_ref:
    zip_ref.extractall(".")

# –û—Ä–≥–∞–Ω–∏–∑–æ–≤–∞—Ç—å –¥–∞–Ω–Ω—ã–µ
import shutil
from sklearn.model_selection import train_test_split
import os

classes = os.listdir("EuroSAT/2750/")
for cls in classes:
    images = os.listdir(f"EuroSAT/2750/{cls}")
    train, test = train_test_split(images, test_size=0.2, random_state=42)

    os.makedirs(f"data/train/{cls}", exist_ok=True)
    os.makedirs(f"data/test/{cls}", exist_ok=True)

    for img in train:
        shutil.copy(f"EuroSAT/2750/{cls}/{img}", f"data/train/{cls}/{img}")

    for img in test:
        shutil.copy(f"EuroSAT/2750/{cls}/{img}", f"data/test/{cls}/{img}")
```

**–®–∞–≥ 2: –ú–æ–¥–µ–ª—å (Day 26-27)**
```python
# models/vegetation_classifier.py
import torch
import torch.nn as nn
import torchvision.models as models

class VegetationClassifier(nn.Module):
    def __init__(self, num_classes=10):
        super().__init__()
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º EfficientNet
        self.backbone = models.efficientnet_b0(pretrained=True)

        # –ó–∞–º–µ–Ω–∏—Ç—å –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä
        num_ftrs = self.backbone.classifier[1].in_features
        self.backbone.classifier = nn.Sequential(
            nn.Linear(num_ftrs, 512),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(512, num_classes)
        )

    def forward(self, x):
        return self.backbone(x)

# Training script
def train_model():
    from torchvision import datasets, transforms
    from torch.utils.data import DataLoader

    # Transforms
    transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.RandomHorizontalFlip(),
        transforms.RandomRotation(15),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])

    # Dataset
    train_dataset = datasets.ImageFolder("data/train", transform=transform)
    test_dataset = datasets.ImageFolder("data/test", transform=transform)

    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
    test_loader = DataLoader(test_dataset, batch_size=32)

    # Model
    model = VegetationClassifier(num_classes=len(train_dataset.classes))
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model = model.to(device)

    criterion = nn.CrossEntropyLoss()
    optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)
    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min')

    # Training
    best_acc = 0.0
    for epoch in range(20):
        model.train()
        running_loss = 0.0

        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)

            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

            running_loss += loss.item()

        # Validation
        model.eval()
        correct = 0
        total = 0

        with torch.no_grad():
            for images, labels in test_loader:
                images, labels = images.to(device), labels.to(device)
                outputs = model(images)
                _, predicted = torch.max(outputs.data, 1)
                total += labels.size(0)
                correct += (predicted == labels).sum().item()

        acc = 100 * correct / total
        print(f'Epoch {epoch+1}: Loss: {running_loss/len(train_loader):.4f}, Acc: {acc:.2f}%')

        # Save best model
        if acc > best_acc:
            best_acc = acc
            torch.save(model.state_dict(), 'best_model.pth')

        scheduler.step(running_loss)

    print(f'Best Accuracy: {best_acc:.2f}%')
    return model

if __name__ == "__main__":
    model = train_model()
```

**–®–∞–≥ 3: Web –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ (Day 28)**
```python
# app.py - Streamlit app
import streamlit as st
import torch
from PIL import Image
from torchvision import transforms
import torch.nn.functional as F

# –ó–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å
@st.cache_resource
def load_model():
    model = VegetationClassifier(num_classes=10)
    model.load_state_dict(torch.load('best_model.pth', map_location='cpu'))
    model.eval()
    return model

model = load_model()

# –ö–ª–∞—Å—Å—ã
classes = ['AnnualCrop', 'Forest', 'HerbaceousVegetation',
           'Highway', 'Industrial', 'Pasture', 'PermanentCrop',
           'Residential', 'River', 'SeaLake']

st.title("üõ∞Ô∏è Satellite Image Vegetation Classifier")

uploaded_file = st.file_uploader("Upload a satellite image", type=["jpg", "png"])

if uploaded_file is not None:
    image = Image.open(uploaded_file).convert('RGB')

    col1, col2 = st.columns(2)

    with col1:
        st.image(image, caption='Uploaded Image', use_column_width=True)

    # Preprocess
    transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])

    input_tensor = transform(image).unsqueeze(0)

    # Predict
    with torch.no_grad():
        outputs = model(input_tensor)
        probs = F.softmax(outputs, dim=1)[0]

    # Show results
    with col2:
        st.subheader("Prediction")
        for i, (cls, prob) in enumerate(sorted(zip(classes, probs), key=lambda x: -x[1])):
            st.write(f"{cls}: {prob*100:.2f}%")
            st.progress(prob.item())
```

**–ó–∞–ø—É—Å–∫:**
```bash
streamlit run app.py
```

---

### –î–µ–Ω—å 29-30: –ü–æ–ª–∏—Ä–æ–≤–∫–∞ –∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è (6-8 —á–∞—Å–æ–≤)

**–î–µ–Ω—å 29: –£–ª—É—á—à–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏**
```bash
# –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Ä–∞–∑–Ω—ã–µ –ø–æ–¥—Ö–æ–¥—ã:
1. –†–∞–∑–Ω—ã–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã (ResNet, EfficientNet, ViT)
2. –†–∞–∑–Ω—ã–µ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏
3. –ì–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã (learning rate, batch size)
4. Semi-supervised —Å CLIP
```

**–î–µ–Ω—å 30: –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è**
```markdown
# README.md

## Vegetation Classification System

### –£—Å—Ç–∞–Ω–æ–≤–∫–∞
```bash
pip install torch torchvision streamlit
```

### –û–±—É—á–µ–Ω–∏–µ
```bash
python train.py
```

### –ó–∞–ø—É—Å–∫
```bash
streamlit run app.py
```

### –†–µ–∑—É–ª—å—Ç–∞—Ç—ã
- Accuracy: 85%
- Model: EfficientNet-B0
- Training time: 2 hours (Colab GPU)

### –ß—Ç–æ –±—ã–ª–æ –∏–∑—É—á–µ–Ω–æ:
- Python fundamentals
- NumPy & Pandas
- OpenCV & Image Processing
- PyTorch & Neural Networks
- CNN & Transfer Learning
- Semi-supervised Learning
- Web Deployment
```

---

## üìö –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ä–µ—Å—É—Ä—Å—ã

### –î–∞—Ç–∞—Å–µ—Ç—ã –¥–ª—è –ø—Ä–∞–∫—Ç–∏–∫–∏:
1. **EuroSAT** - –°–ø—É—Ç–Ω–∏–∫–æ–≤—ã–µ —Å–Ω–∏–º–∫–∏ (10 –∫–ª–∞—Å—Å–æ–≤)
   - https://github.com/phelber/EuroSAT

2. **UC Merced Land Use** - –ì–æ—Ä–æ–¥—Å–∫–∏–µ —Ç–µ—Ä—Ä–∏—Ç–æ—Ä–∏–∏
   - http://weegee.vision.ucmerced.edu/datasets/landuse.html

3. **DeepGlobe** - –°–ø—É—Ç–Ω–∏–∫–æ–≤—ã–µ —Å–Ω–∏–º–∫–∏ –¥–ª—è —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏
   - https://competitions.codalab.org/competitions/18468

### –ë–µ—Å–ø–ª–∞—Ç–Ω—ã–µ GPU:
- **Google Colab** - https://colab.research.google.com/
- **Kaggle Notebooks** - https://www.kaggle.com/code

### –ö–Ω–∏–≥–∏:
- "Hands-On Machine Learning with Scikit-Learn and TensorFlow" - Aur√©lien G√©ron
- "Deep Learning" - Ian Goodfellow (–±–µ—Å–ø–ª–∞—Ç–Ω–æ –æ–Ω–ª–∞–π–Ω)

### –ö–∞–Ω–∞–ª—ã YouTube:
- **3Blue1Brown** - –ú–∞—Ç–µ–º–∞—Ç–∏–∫–∞ ML
- **Sentdex** - –ü—Ä–∞–∫—Ç–∏–∫–∞ ML
- **Krish Naik** - ML —Ç—É—Ç–æ—Ä–∏–∞–ª—ã

---

## ‚úÖ –ß–µ–∫-–ª–∏—Å—Ç –ø—Ä–æ–≥—Ä–µ—Å—Å–∞

### –ù–µ–¥–µ–ª—è 1:
- [ ] Python basics
- [ ] NumPy operations
- [ ] Pandas data manipulation
- [ ] Scikit-learn basics

### –ù–µ–¥–µ–ª—è 2:
- [ ] OpenCV image processing
- [ ] Rasterio satellite data
- [ ] NDVI calculation
- [ ] PyTorch tensors
- [ ] Simple neural network

### –ù–µ–¥–µ–ª—è 3:
- [ ] CNN architecture
- [ ] Training CNN
- [ ] Transfer learning
- [ ] Data augmentation

### –ù–µ–¥–µ–ª—è 4:
- [ ] Semi-supervised learning
- [ ] CLIP prompts
- [ ] Final project
- [ ] Web deployment

---

## üí° –°–æ–≤–µ—Ç—ã –¥–ª—è —É—Å–ø–µ—Ö–∞

1. **–ü—Ä–∞–∫—Ç–∏–∫–∞ > –¢–µ–æ—Ä–∏—è**: 70% –≤—Ä–µ–º–µ–Ω–∏ –ø–∏—à–∏—Ç–µ –∫–æ–¥, 30% —Å–º–æ—Ç—Ä–∏—Ç–µ –≤–∏–¥–µ–æ
2. **–ù–µ –∑–∞—Å—Ç—Ä–µ–≤–∞–π—Ç–µ**: –ï—Å–ª–∏ —Ç–µ–º–∞ —Å–ª–æ–∂–Ω–∞—è, –¥–≤–∏–≥–∞–π—Ç–µ—Å—å –¥–∞–ª—å—à–µ, –≤–µ—Ä–Ω–µ—Ç–µ—Å—å –ø–æ–∑–∂–µ
3. **–î–µ–ª–∞–π—Ç–µ –∑–∞–º–µ—Ç–∫–∏**: –í–µ–¥–∏—Ç–µ Jupyter Notebook —Å –ø—Ä–∏–º–µ—Ä–∞–º–∏ –∫–æ–¥–∞
4. **–ü—Ä–∏—Å–æ–µ–¥–∏–Ω—è–π—Ç–µ—Å—å –∫ —Å–æ–æ–±—â–µ—Å—Ç–≤—É**: Kaggle, Reddit r/MachineLearning
5. **–ù–∞—á–Ω–∏—Ç–µ —Å –ø—Ä–æ—Å—Ç–æ–≥–æ**: –ù–µ –ø—ã—Ç–∞–π—Ç–µ—Å—å —Å—Ä–∞–∑—É —Å–¥–µ–ª–∞—Ç—å —Å–ª–æ–∂–Ω—É—é –º–æ–¥–µ–ª—å

---

## üéØ –û–∂–∏–¥–∞–µ–º—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —á–µ—Ä–µ–∑ 30 –¥–Ω–µ–π

–í—ã —Å–º–æ–∂–µ—Ç–µ:
- ‚úÖ –ü–∏—Å–∞—Ç—å –∫–æ–¥ –Ω–∞ Python –¥–ª—è ML
- ‚úÖ –°—Ç—Ä–æ–∏—Ç—å –∏ –æ–±—É—á–∞—Ç—å –Ω–µ–π—Ä–æ—Å–µ—Ç–∏
- ‚úÖ –ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å —Å–ø—É—Ç–Ω–∏–∫–æ–≤—ã–µ —Å–Ω–∏–º–∫–∏
- ‚úÖ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å transfer learning
- ‚úÖ –°–æ–∑–¥–∞–≤–∞—Ç—å web –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è —Å ML
- ‚úÖ –ü–æ–Ω–∏–º–∞—Ç—å –±–∞–∑–æ–≤—ã–µ –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏ semi-supervised learning

**–£–¥–∞—á–∏ –≤ –æ–±—É—á–µ–Ω–∏–∏! üöÄ**
